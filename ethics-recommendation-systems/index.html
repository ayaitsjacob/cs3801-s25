<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Ethics of Recommendation Systems</title>
	<link href="/assets/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="/assets/css/ionicons.min.css">
	<link href="https://fonts.googleapis.com/css?family=Istok+Web:400,400i,700,700i" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=PT+Sans" rel="stylesheet">

	<link href="/assets/css/main.css" rel="stylesheet">


</head>

<body>
	<div id="preloader"></div>
	<div class="body-content" style="display:none;">
		<div id="elements-page-wrapper">
			<div class="navbar-solid-state">
				<header id="header" class="alt">
					<nav>
						<a href="#menu" class="a-menu">Menu <i class="ion-android-menu"></i> </a>
					</nav>
				</header>

				<nav id="menu">
					<div class="inner">
						<h2>Menu</h2>
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
						<a href="#" class="close">Close</a>
					</div>
				</nav>
			</div>

			<section id="element-header" class="elements-header">
				<div class="overlay"></div>
				<div class="container">
					<div class="row">
						<div class="header-design">
							<div class="col-md-12">
								<h1 class="elements-h">Ethics of Recommendation Systems</h1>
							</div>
							<div class="col-md-12">
								<br>
								<br>
								<br>
								<br>
								<br>
								<br>
								<br>
								<br>
								<br>
								<br>
								<br>
								<br>
								<P>
									Recommendation systems have become an integral part of our digital experience,
									quietly shaping what we
									watch, listen to, and read. Platforms like TikTok, YouTube, and Spotify rely on
									sophisticated algorithms that
									analyze vast amounts of user behavior—what we click on, how long we linger, what we
									skip—to predict and
									deliver content tailored to individual tastes. On the surface, these personalized
									feeds promise convenience
									and discovery: they help us unearth new music, find niche communities, or stay up to
									date on topics we care
									about. Yet behind every seamless scroll or curated playlist lies a complex interplay
									of data collection,
									machine learning models, and commercial objectives.
								</P>
							</div>
						</div>
					</div>
				</div>
			</section>
			<section id="elements-one">
				<div class="container">
					<div class="row">
						<div class="elements-one-design">
							<div class="col-md-12">
								<br>
								<br>
								<br>
								<h1 class="elements-h">Application of a Recommendation System:</h1>
								<h2>Instagram</h2>
							</div>
							<br>
							<br>
							<br>
							<div class="col-md-12">
								<br>
								<p>
									Instagram’s algorithm decides what posts, reels, and ads you see based on what you
									like and watch.
									This keeps users hooked but also causes problems like privacy issues, unfair biases,
									and harm to mental health.
								</p>
								<br>
								<br>
								<br>
								<h2>How It Works</h2>
								<br>
								<p>
									The algorithm tracks everything—likes, comments, time spent—to show more of what you
									engage with.
									This can trap users in a "bubble" where they only see similar content, hiding
									different opinions.
									For example, if you watch fitness videos, you’ll keep seeing them, even if it makes
									you feel bad about your body.
								</p>
								<br>
								<br>
								<br>
								<h2>Privacy Problems</h2>
								<br>
								<p>
									Instagram collects tons of personal data, like location and search history, to
									target ads and content.
									Most people don’t realize how much info is taken or who gets access to it.
									This lack of control over personal data is a big ethical concern.
								</p>
								<br>
								<br>
								<br>
								<h2>Mental Health Risks</h2>
								<br>
								<p>
									The app pushes addictive content, like perfect-looking photos or extreme opinions,
									because it gets more clicks.
									Studies show this can increase anxiety and depression, especially in young people.
									The endless scroll and notifications make it hard to stop using the app, which feels
									manipulative.
								</p>
								<br>
								<br>
								<br>
								<h2>Bias in Recommendations</h2>
								<br>
								<p>

									Sometimes, the algorithm favors certain groups unfairly.
									For example, job ads might mostly show to men, or beauty standards might focus on
									one body type.
									Since the system learns from past data, it can repeat real-world biases without
									meaning to.
								</p>
								<br>
								<br>
								<br>
								<h2>Lack of Transparency</h2>
								<br>
								<p>
									Nobody really knows how Instagram’s algorithm picks content.
									Users can’t see why certain posts appear, and some people (like activists or
									minority groups) get hidden unfairly.
									More openness would help users trust the platform.
								</p>
							</div>
						</div>

						<div class="elements-blockquote">
							<div class="col-md-12">
								<h1 class="elements-h">Targeted Recommendations Lead to Body Dysphoria:</h1>
								<h2>Real World Example</h2>
							</div>

							<div class="col-md-12">
								<br>
								<p>
									An article from the Tech Transparency Project (TTP) details a disturbing trend the
									Instagram recommendation system follows.
									In the article, they made an account that presented itself as a 14-year-old girl,
									had her follow thin-adjacent accounts, then, simply watched.
									In summary, they found their account was thrown into a perpetuating negative
									feedback loop of body shaming content.
									Unhealthy eating standards were standard viewing, such as anorexia, and extreme
									weight loss.

									In short, Instagram is incredibly successful at locating user interests, thus, will
									continue to promote similar posts.
									The artificial account was concerned with weight, so Instagram promoted content it
									thought could satisfy the user's concern.
									Then, by engaging with that content, Instagram would include that video into its
									recommendation pool.
									Thereby affirming to the system that the user likes said content, meaning it should
									recommend more.

									This is also a gradual process, as the user continues to engage, the content will
									escalate.
									The user will encounter more and more extreme world views from fringe content
									creators.
									Like sticking your head in a hole, the deeper you go, the darker everything gets.

									This leads to the user falling into a bubble, where all they are recommended are
									videos that attack their self image.
									Worse yet, because that is the only content they perceive, this gives them a warped
									view on reality.
									Believing now that in order to fit in, they need to continue following these videos.

									Instagram is a very accomodating system, always circulating the hottest, newest
									content for users.
									As a reliable source of homegrown entertainment and information, there is a lot of
									user trust.
									Users are exposed to harmful, biased content loops because they trust Instagram, and
									its recommendation system is always punctual.
									The consequence of this punctuality means it has to scrape the bottom of the barrel
									to find suitable videos for the user.
									Finally, again, if the user engages with it, that only affirms to the system that
									the user wants to see more.
								</p>
							</div>
						</div>

						<div class="elements-list">

							<div class="col-md-12">
								<h1 class="elements-h">Applying A Framwork:</h1>
								<h2>Kantianism</h2>
							</div>


							<div class="col-md-12">
								<br>

								<p>
									Much of the problem stems from warped reality/bubble issues.
									Impressionable users are either misled to harmful opinions, or shuffled to the side
									and recommended alienating content.
									Instagram is, first and foremost, an engagement service.
									This means it WILL advertise provocative content if it means more user engagement.

									The practical solution is to apply Kant's ethical framework of transparency.
									Informing users on how their viewing habits/data are utilized for recommendations,
									and providing adequate services to opt out.
									At the heart of Kant, proper notification and disclaimer are really all an online
									service needs/should provide.
									Like putting up signs that warn of an active minefield on the way to the grocery
									store.
									Leave it to the whims of the individual how they should proceed from there.

								</p>
							</div>

							<div class="col-md-12">
								<ul>
									<li>
										Let users turn off the algorithm and see posts in order.
									</li>
									<li>
										Be clearer about how data is used.
									</li>
									<li>
										Check for bias and fix unfair trends.
									</li>
									<li>
										Reduce features that make the app too addictive.
									</li>
								</ul>
							</div>
						</div>

						<div class="elements-list">

							<div class="col-md-12">
								<h1 class="elements-h">Conclusion</h1>
							</div>

							<div class="col-md-12">
								<p>
									Instagram’s recommendations keep people scrolling but have serious downsides.
									The company should focus less on profit and more on user safety and fairness.
									Small changes could make the app healthier for everyone.
								</p>
							</div>

							<div class="col-md-12 author-note-container">
								<h1 class="elements-h">Author's Note</h1>
								<p>
									Our group took time together to brainstorm the landscape of recommendation systems
									and how it affects us.
									We used that basis to build up our argument and perspective.
									Kept up correspondence and updates on our progress.
								</p>
							</div>
						</div>

					</div>
				</div>
			</section>

		</div>
	</div>
	<script src="/assets/js/jquery.min.js"></script>
	<script src="/assets/js/bootstrap.min.js"></script>
	<script src="/assets/js/main.js"></script>
</body>

</html>